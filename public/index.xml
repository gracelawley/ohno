<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Grace Olive Lawley on Grace Olive Lawley</title>
    <link>/</link>
    <description>Recent content in Grace Olive Lawley on Grace Olive Lawley</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2018 Grace Lawley</copyright>
    <lastBuildDate>Sun, 15 Oct 2017 00:00:00 -0700</lastBuildDate>
    <atom:link href="/" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Kuczaj Corpus Sentiment Analysis, Part 2</title>
      <link>/project/kuczaj_pt2/</link>
      <pubDate>Wed, 08 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>/project/kuczaj_pt2/</guid>
      <description>&lt;p&gt;This past June, I did a &lt;a href=&#34;https://grace.rbind.io/project/final_vis/&#34;&gt;sentiment analysis of the Kuczaj Corpus&lt;/a&gt; from the CHILDES database for my final project in the Data Visualization class taught by Alison Presmanes Hill, Steven Bedrick, and Jackie Wirz. During my presentation some of the questions that came up were: Does the total number of words per transcript vary a lot? How much is this effecting the sentiment analysis? What would happen to the plot if I normalized for transcript length?&lt;/p&gt;
&lt;p&gt;The length of the transcripts &lt;em&gt;does&lt;/em&gt; vary a great deal, both before and after processing and filtering against the nrc sentiment lexicon. I had actually noticed this artifact in the dataset when working on the project and had plans to address it. I ended up not having enough time to explore different normalization techniques and included a limitations section discussing how this could affect the visualizations I created.&lt;/p&gt;
&lt;p&gt;Now, two months later, I am revisiting these questions and am going to find out what will happen if I normalize for transcript length!&lt;/p&gt;
&lt;p&gt;Here are the packages that I will be using:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Loading packages
library(tidyverse)
library(tidytext)
library(forcats)
library(skimr)
library(egg)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I saved the version of the dataset that I used to create the ridgeline density plots as a csv file so I could pick up where I left off.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# reading in data
kuczaj &amp;lt;- read_csv(&amp;quot;data/kuczaj_nrc.csv&amp;quot;)     &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here’s a glimpse of what &lt;code&gt;kuczaj&lt;/code&gt; looks like:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;glimpse(kuczaj)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Observations: 22,893
## Variables: 4
## $ age_months &amp;lt;dbl&amp;gt; 29.00060, 29.00060, 29.00060, 29.00060, 29.00060, 2...
## $ age_years  &amp;lt;dbl&amp;gt; 2.416716, 2.416716, 2.416716, 2.416716, 2.416716, 2...
## $ word       &amp;lt;chr&amp;gt; &amp;quot;hurt&amp;quot;, &amp;quot;hurt&amp;quot;, &amp;quot;hurt&amp;quot;, &amp;quot;hurt&amp;quot;, &amp;quot;break&amp;quot;, &amp;quot;cry&amp;quot;, &amp;quot;cr...
## $ sentiment  &amp;lt;chr&amp;gt; &amp;quot;anger&amp;quot;, &amp;quot;fear&amp;quot;, &amp;quot;negative&amp;quot;, &amp;quot;sadness&amp;quot;, &amp;quot;surprise&amp;quot;,...&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Since I only worked with the “trust”, “joy”, “anticipation”, “sadness”, “fear”, and “anger” sentiments last time, I am going to filter out all other sentiments from the dataframe. I’m also going to coerce &lt;code&gt;sentiment&lt;/code&gt; to a factor and will order its levels with the positively associated ones before the negatively associated ones to make plotting easier later on.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Sentiments to keep
sentiment_levels &amp;lt;- c(&amp;quot;trust&amp;quot;, &amp;quot;joy&amp;quot;, &amp;quot;anticipation&amp;quot;, 
                      &amp;quot;sadness&amp;quot;, &amp;quot;fear&amp;quot;, &amp;quot;anger&amp;quot;)

# Making sentiment a factor
kuczaj &amp;lt;- kuczaj %&amp;gt;% 
  select(-age_years, -word) %&amp;gt;% # removing unneeded columns
  filter(sentiment %in% sentiment_levels) %&amp;gt;% 
  mutate(sentiment = factor(sentiment, levels = sentiment_levels))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The transcripts were collected very frequently, so there end up being separate transcripts when Abe is 30.13204, 30.19775, and 30.32916 months old. There are 207 unique values of &lt;code&gt;age_month&lt;/code&gt; alone. To make the data easier to plot, I chose to bin the observations together by taking the floor of &lt;code&gt;age_months&lt;/code&gt; and then normalizing each unique age bin. This brings down the total unique values of &lt;code&gt;age_month&lt;/code&gt; to 33, which will be a lot easier to plot. I also chose to remove the observations that fall into the edge age bins so that only “complete” bins are included.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Taking the floor of age_months
ages_binned &amp;lt;- kuczaj %&amp;gt;% 
  mutate(age_months = floor(age_months)) 


# Removing the two edge bins
ages_binned &amp;lt;- ages_binned %&amp;gt;% 
  filter(age_months &amp;gt;= 29 &amp;amp; age_months &amp;lt;= 60)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To normalize by transcript length, for each of the age bins, I will count the total times each of the 6 sentiments is observed and then divide that number by the total number of sentiment tokens observed.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Counting the number of sentiments 
ages_binned &amp;lt;- ages_binned %&amp;gt;% 
  add_count(age_months, sentiment) %&amp;gt;% 
  rename(n_sentiment = n) %&amp;gt;% 
  distinct(age_months, sentiment, .keep_all = TRUE)


# Adding in count for total tokens per transcript that were kept
ages_binned &amp;lt;- ages_binned %&amp;gt;% 
  group_by(age_months) %&amp;gt;% 
  mutate(n_tokens = sum(n_sentiment)) %&amp;gt;% 
  ungroup()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Before I can move on to dividing &lt;code&gt;n_sentiment&lt;/code&gt; by &lt;code&gt;n_tokens&lt;/code&gt;, I first have to add in rows for when a sentiment is not observed for a particular age bin. Since I used &lt;code&gt;add_count&lt;/code&gt; to calculate &lt;code&gt;n_sentiment&lt;/code&gt;, I’m missing these 0 value rows in my dataframe currently. Using the &lt;code&gt;expand()&lt;/code&gt; function from the &lt;code&gt;tidyr&lt;/code&gt; package, I can create a dataframe, &lt;code&gt;aux&lt;/code&gt;, that has all possible combinations of &lt;code&gt;age_months&lt;/code&gt;, &lt;code&gt;n_tokens&lt;/code&gt; and &lt;code&gt;sentiment&lt;/code&gt;. I can then join this dataframe with my &lt;code&gt;ages_binned&lt;/code&gt; dataframe to have rows for all 6 sentiments for each age bin.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Creating the auxiliary table with all combinations
aux &amp;lt;- ages_binned %&amp;gt;% 
  expand(nesting(age_months, n_tokens), sentiment)

# Merging aux with ages_binned
ages_binned2 &amp;lt;- aux %&amp;gt;% 
  left_join(ages_binned, by = c(&amp;quot;age_months&amp;quot;, &amp;quot;n_tokens&amp;quot;, &amp;quot;sentiment&amp;quot;)) %&amp;gt;% 
  replace_na(list(n_sentiment = 0)) # replacing NA values with 0&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now, I can normalize! I calculate the &lt;code&gt;percent&lt;/code&gt; column by dividing the number of tokens of each sentiment for each age bin by the total number of tokens for that age bin overall.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Normalizing!
ages_binned2 &amp;lt;- ages_binned2 %&amp;gt;% 
  mutate(percent = n_sentiment/n_tokens)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;It is important to note the number of tokens in each age bin varies a lot. How much does it vary?&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(ages_binned2, aes(age_months, n_tokens)) +
  geom_point() + 
  labs(title = &amp;quot;Total number of tokens per age bin&amp;quot;) +
  theme_minimal()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/project/kuczaj_pt2_files/figure-html/bins-1.png&#34; width=&#34;3000&#34; /&gt;
I decided to move forward for this iteration of the project without addressing this further but would ideally like to explore some weighting options in the future. So please just keep these limitations in mind when viewing the visualizations that follow.&lt;/p&gt;
&lt;p&gt;To get orientated with the data I started by making this quick and minimal scatterplot.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(ages_binned2, aes(age_months, percent, color = sentiment)) +
  geom_point(alpha = 0.7) +
  facet_wrap(~ sentiment) +
  guides(color = FALSE) +
  theme_minimal()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/project/kuczaj_pt2_files/figure-html/plot1-1.png&#34; width=&#34;3000&#34; /&gt;&lt;/p&gt;
&lt;p&gt;…and then on second thought, I decided to switch over to a bar chart.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(ages_binned2, aes(age_months, percent, fill = sentiment)) +
  geom_col(alpha = 0.7) +
  facet_grid(sentiment ~ .)+
  guides(fill = FALSE) +
  theme_minimal()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/project/kuczaj_pt2_files/figure-html/plot2-1.png&#34; width=&#34;3000&#34; /&gt;&lt;/p&gt;
&lt;p&gt;This looks better, but having all six plots in one column makes the plots look a little cramped. What if I used a &lt;code&gt;facet_wrap&lt;/code&gt; on sentiment?&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(ages_binned2, aes(age_months, percent, fill = sentiment)) +
  geom_col(alpha = 0.7) +
  facet_wrap(~ sentiment) + 
  theme_minimal() +
  labs(x = &amp;quot;&amp;quot;, y = &amp;quot;&amp;quot;) +
  guides(fill = FALSE)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/project/kuczaj_pt2_files/figure-html/plot3-1.png&#34; width=&#34;3000&#34; /&gt;&lt;/p&gt;
&lt;p&gt;…what if I switch the orientation and add in some colors?&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;positive_plot &amp;lt;- ages_binned2 %&amp;gt;% 
  filter(sentiment %in% c(&amp;quot;trust&amp;quot;, &amp;quot;joy&amp;quot;, &amp;quot;anticipation&amp;quot;)) %&amp;gt;% 
  ggplot(aes(age_months, percent, fill = sentiment)) +
    geom_col(alpha = 0.7, color = &amp;quot;white&amp;quot;) +
    facet_wrap(~sentiment, ncol = 1, scale = &amp;quot;free_x&amp;quot;) +
    theme_minimal() +
    labs(x = &amp;quot;&amp;quot;, y = &amp;quot;&amp;quot;, title = &amp;quot;Kuczaj Corpus &amp;amp; Sentiment&amp;quot;) +
    guides(fill = FALSE) +
    scale_fill_manual(values = c(&amp;quot;#97B8C7&amp;quot;, &amp;quot;#AEC9C3&amp;quot;, &amp;quot;#7FCCD3&amp;quot;)) 

negative_plot &amp;lt;- ages_binned2 %&amp;gt;% 
  filter(sentiment %in% c(&amp;quot;sadness&amp;quot;, &amp;quot;fear&amp;quot;, &amp;quot;anger&amp;quot;)) %&amp;gt;% 
  ggplot(aes(age_months, percent, fill = sentiment)) +
    geom_col(alpha = 0.7, color = &amp;quot;white&amp;quot;) +
    facet_wrap(~sentiment, ncol = 1, scale = &amp;quot;free_x&amp;quot;) +
    theme_minimal() +
    labs(x = &amp;quot;&amp;quot;, y = &amp;quot;&amp;quot;) +
    guides(fill = FALSE) +
    scale_fill_manual(values = c(&amp;quot;#21132B&amp;quot;, &amp;quot;#4F406E&amp;quot;, &amp;quot;#6C7399&amp;quot;))

ggarrange(positive_plot, negative_plot, ncol = 2, nrow = 1)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/project/kuczaj_pt2_files/figure-html/plot4-1.png&#34; width=&#34;3000&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Okay, I like this one a lot more. Now let’s customize the axis tick breaks and labels.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;positive_plot2 &amp;lt;- positive_plot +
  scale_y_continuous(breaks = c(0.05, 0.15, 0.25),
                     labels = c(&amp;quot;5%&amp;quot;, &amp;quot;15%&amp;quot;, &amp;quot;25%&amp;quot;)) +
  scale_x_continuous(breaks = c(30, 36, 42, 48, 54, 60),
                     labels = c(&amp;quot;2.5 yrs&amp;quot;, &amp;quot;3 yrs&amp;quot;, &amp;quot;3.5 yrs&amp;quot;, &amp;quot;4 yrs&amp;quot;, &amp;quot;4.5 yrs&amp;quot;, &amp;quot;5 yrs&amp;quot;)) 

negative_plot2 &amp;lt;- negative_plot +
  scale_y_continuous(breaks = c(0.05, 0.15, 0.25),
                     labels = c(&amp;quot;5%&amp;quot;, &amp;quot;15%&amp;quot;, &amp;quot;25%&amp;quot;)) +
  scale_x_continuous(breaks = c(30, 36, 42, 48, 54, 60),
                     labels = c(&amp;quot;2.5 yrs&amp;quot;, &amp;quot;3 yrs&amp;quot;, &amp;quot;3.5 yrs&amp;quot;, &amp;quot;4 yrs&amp;quot;, &amp;quot;4.5 yrs&amp;quot;, &amp;quot;5 yrs&amp;quot;)) 


ggarrange(positive_plot2, negative_plot2, ncol = 2, nrow = 1)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/project/kuczaj_pt2_files/figure-html/plot4a-1.png&#34; width=&#34;3000&#34; /&gt;&lt;/p&gt;
&lt;p&gt;…and finally let’s change the font face and add in tick marks!&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;positive_plot3 &amp;lt;- positive_plot2 +
  theme(plot.title = element_text(size = 18, face = &amp;quot;bold&amp;quot;),
        strip.text = element_text(size = 15, face = &amp;quot;italic&amp;quot;),
        axis.text.x = element_text(size = 10, face = &amp;quot;italic&amp;quot;),
        axis.text.y = element_text(size = 10, face = &amp;quot;italic&amp;quot;),
        axis.ticks.x = element_line())

negative_plot3 &amp;lt;- negative_plot2 +
  theme(strip.text = element_text(size = 15, face = &amp;quot;italic&amp;quot;),
        axis.text.x = element_text(size = 10, face = &amp;quot;italic&amp;quot;),
        axis.text.y = element_text(size = 10, face = &amp;quot;italic&amp;quot;),
        axis.ticks.x = element_line())

ggarrange(positive_plot3, negative_plot3, ncol = 2, nrow = 1)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/project/kuczaj_pt2_files/figure-html/plot4b-1.png&#34; width=&#34;3000&#34; /&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Kuczaj Corpus Sentiment Analysis, part 1 </title>
      <link>/project/final_vis/</link>
      <pubDate>Sun, 17 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>/project/final_vis/</guid>
      <description>&lt;div id=&#34;ridgeline-plot&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Ridgeline Plot&lt;/h1&gt;
&lt;p&gt;&lt;img src=&#34;/project/final_vis_files/figure-html/intial%20plot-1.png&#34; width=&#34;960&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;description-of-the-data&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Description of the Data&lt;/h1&gt;
&lt;p&gt;Over the past few weeks of my research I have been wrangling and exploring a subset of data from the &lt;a href=&#34;https://childes.talkbank.org/&#34;&gt;Child Language Data Exchange System&lt;/a&gt; (CHILDES), an enormous online repository of language acquisition data that is available online for free. The data that I have been studying is a subset of 14 corpora from the &lt;em&gt;Eng-NA&lt;/em&gt; section of CHILDES. The &lt;em&gt;Eng-NA&lt;/em&gt; section contains 50+ individual corpora with language acquisition data of exclusively North American English.&lt;/p&gt;
&lt;p&gt;Though I have spent a lot of time with this dataset, I haven’t had many opportunities to visualize it yet. For my final visualization project, I decided to work with one of the 14 corpora that I have been exploring, the &lt;a href=&#34;https://childes.talkbank.org/access/Eng-NA/Kuczaj.html&#34;&gt;Kuczaj Corpus&lt;/a&gt;. The Kuczaj Corpus contains transcripts of spontaneous speech collected during a longitudinal case study conducted by Stan Kuczaj on his son, Abe. Kuczaj was studying the acquisition of certain verb inflections. The study took place from 1973-1975, when Abe was 28 months old to 60 months old.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;creating-the-visualization&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Creating the Visualization&lt;/h1&gt;
&lt;p&gt;The raw data used for this project was gathered from the CHILDES database via the &lt;code&gt;childesr&lt;/code&gt; package. Since I was interested in examining the speech of Abe, I pulled down all of his utterances across the entire corpus.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Loading packages
library(childesr)
library(magrittr)
library(tidytext)
library(ggridges)
library(ggplot2)
library(stringr)
library(dplyr)
library(tidyr)
library(egg)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Pulling down the raw utterances from the childes db
kuczaj_raw &amp;lt;- childesr::get_utterances(collection = &amp;quot;Eng-NA&amp;quot;,
                                       corpus = &amp;quot;Kuczaj&amp;quot;,
                                       role = &amp;quot;Target_Child&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Before I could begin making my visualization, there was quite a bit of data organizing and data cleaning that had to be done first. I started by rearranging the raw dataframe, &lt;code&gt;kuczaj_raw&lt;/code&gt;, and removed any columns that I would not be needing later on. Unlike other corpora included in the CHILDES database, the Kuczaj Corpus only has one target child. A lot of the metadata about the corpora and the texts was not needed because of this, and I only ended up keeping two columns: &lt;code&gt;gloss&lt;/code&gt; (the utterance) and &lt;code&gt;target_child_age&lt;/code&gt; (age at time of utterance in months). After reorganizing the columns, I made sure to filter out any missing utterances that there might be in the dataset.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Rearrange/renaming columns and removing missing utterances
kuczaj &amp;lt;- kuczaj_raw %&amp;gt;% 
  select(utt = gloss, age_months = target_child_age) %&amp;gt;% 
  drop_na(utt) %&amp;gt;% 
  filter(utt != &amp;quot;&amp;quot;) &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Once the reorganization was finished, I began working on cleaning the data. I standarized all contractions that occured. Contractions were either expanded or collapsed, depending on whether they were an exception case or a general case. I made a subjective decision to remove all occurences of &lt;code&gt;&#39;s&lt;/code&gt;, since its grammatical meaning is ambiguous: it can either signify a possessive &lt;code&gt;&#39;s&lt;/code&gt; or a collapsed &lt;code&gt;is&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;In addition to processing contractions, I also removed all underscores (used to signify a phrase), and converted all characters to lowercase.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Creating a function to process contractions

proc_contractions &amp;lt;- function(string) {
  string %&amp;lt;&amp;gt;%
    # Expanding the exception cases
    str_replace_all(&amp;quot;won&amp;#39;t&amp;quot;, &amp;quot;will not&amp;quot;) %&amp;gt;%
    str_replace_all(&amp;quot;can&amp;#39;t&amp;quot;, &amp;quot;can not&amp;quot;) %&amp;gt;%
    str_replace_all(&amp;quot;c&amp;#39;mon&amp;quot;, &amp;quot;come on&amp;quot;) %&amp;gt;% 
    str_replace_all(&amp;quot;let&amp;#39;s&amp;quot;, &amp;quot;let us&amp;quot;) %&amp;gt;% 
    str_replace_all(&amp;quot;shan&amp;#39;t&amp;quot;, &amp;quot;shall not&amp;quot;) %&amp;gt;% 
    str_replace_all(&amp;quot;y&amp;#39;all&amp;quot;, &amp;quot;you all&amp;quot;) %&amp;gt;% 
    
    # Collapsing &amp;quot;o&amp;#39;clock&amp;quot; bc the expansion, &amp;quot;of the clock&amp;quot; is uncommon/archaic
    str_replace_all(&amp;quot;o&amp;#39;clock&amp;quot;, &amp;quot;oclock&amp;quot;) %&amp;gt;%
    
    # Collapsing &amp;quot;ain&amp;#39;t&amp;quot; bc the expansion is ambiguous
    str_replace_all(&amp;quot;ain&amp;#39;t&amp;quot;, &amp;quot;aint&amp;quot;) %&amp;gt;%
    
    # Expanding the general cases
    str_replace_all(&amp;quot;&amp;#39;m&amp;quot;, &amp;quot; am&amp;quot;) %&amp;gt;%
    str_replace_all(&amp;quot;n&amp;#39;t&amp;quot;, &amp;quot; not&amp;quot;) %&amp;gt;%
    str_replace_all(&amp;quot;&amp;#39;ll&amp;quot;, &amp;quot; will&amp;quot;) %&amp;gt;%
    str_replace_all(&amp;quot;&amp;#39;d&amp;quot;, &amp;quot; would&amp;quot;) %&amp;gt;%
    str_replace_all(&amp;quot;&amp;#39;ve&amp;quot;, &amp;quot; have&amp;quot;) %&amp;gt;%
    str_replace_all(&amp;quot;n&amp;#39;ts&amp;quot;, &amp;quot; nots&amp;quot;) %&amp;gt;%
    str_replace_all(&amp;quot;&amp;#39;re&amp;quot;, &amp;quot; are&amp;quot;) %&amp;gt;%
    
    # Removing all &amp;quot;&amp;#39;s&amp;quot; bc the expansion is ambiguous (possessive or &amp;quot; is&amp;quot;)
    str_replace_all(&amp;quot;&amp;#39;s&amp;quot;, &amp;quot;&amp;quot;) %&amp;gt;%
    
    # Catching any missed apostrophes
    str_replace_all(&amp;quot;&amp;#39;&amp;quot;, &amp;quot;&amp;quot;)
  
  return(string)
}&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Processing utterances
kuczaj$utt %&amp;lt;&amp;gt;%
  
  # Removing all underscores
  str_replace_all(&amp;quot;_&amp;quot;, &amp;quot; &amp;quot;) %&amp;gt;% 
  
  # Processing contractions
  proc_contractions() %&amp;gt;% 
  
  # Changing all characters to lowercase
  str_to_lower()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Since the age of a person is typically quantified and referred to in years instead of months, I decided to convert the unit that records age in the dataframe to years instead of months.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Adding a column with age in years
kuczaj %&amp;lt;&amp;gt;%
  mutate(age_years = age_months/12)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Next, I unnested the utterances into tokens. For this visualization I chose to tokenizing the text into unigrams using the &lt;code&gt;unnest_tokens()&lt;/code&gt; function from the &lt;code&gt;tidytext&lt;/code&gt; package.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Tokenizing into unigrams
tokens_raw &amp;lt;- kuczaj %&amp;gt;% 
  unnest_tokens(output = word, input = utt)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Since text data can be difficult to visualize raw, especially if you have a lot of it, I chose to visualize the emotion in the text. I performed a sentiment analysis with the &lt;code&gt;&amp;quot;nrc&amp;quot;&lt;/code&gt; sentiment lexicon included in the &lt;code&gt;tidytext&lt;/code&gt; package. The &lt;a href=&#34;http://saifmohammad.com/WebPages/NRC-Emotion-Lexicon.htm&#34;&gt;NRC Word-Emotion Association Lexicon&lt;/a&gt; classifies words into 10 different sentiment categories: &lt;code&gt;anger&lt;/code&gt;, &lt;code&gt;anticipation&lt;/code&gt;, &lt;code&gt;disgust&lt;/code&gt;, &lt;code&gt;fear&lt;/code&gt;, &lt;code&gt;joy&lt;/code&gt;, &lt;code&gt;negative&lt;/code&gt;, &lt;code&gt;positive&lt;/code&gt;, &lt;code&gt;sadness&lt;/code&gt;, &lt;code&gt;surprise&lt;/code&gt;, and &lt;code&gt;trust&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;After initializing the lexicon, I combined it with the tokens using an &lt;code&gt;dplyr::inner_join&lt;/code&gt;. Only the tokens that occured in both dataframes were kept, while all other tokens were removed.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Initizalizing &amp;quot;nrc&amp;quot; sentiment lexicon
nrc &amp;lt;- tidytext::get_sentiments(&amp;quot;nrc&amp;quot;)

# Merging together tokens and nrc
nrc_df &amp;lt;- tokens_raw %&amp;gt;% 
  inner_join(nrc, by = &amp;quot;word&amp;quot;)  &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As is typical and potentially problematic of sentiment lexicons, a lot of words ended up being omitted. The total number of tokens changed from 167833 to 22893, with 144940 tokens lost.&lt;/p&gt;
&lt;p&gt;And finally, making the plot!&lt;/p&gt;
&lt;p&gt;I decided to restrict the sentiment categories from 10 to 6, and grouped these 6 into emotions that associated with a positive sentiment – &lt;code&gt;joy&lt;/code&gt;, &lt;code&gt;trust&lt;/code&gt;, and &lt;code&gt;anticipation&lt;/code&gt; – and emotions that are associated with a negative sentiment – &lt;code&gt;anger&lt;/code&gt;, &lt;code&gt;sadness&lt;/code&gt;, and &lt;code&gt;fear&lt;/code&gt;. The creation of these groupings was mostly a subjective decision that was partially motivated from exploring the most common sets of emotions as illustrated on the &lt;a href=&#34;http://saifmohammad.com/WebPages/NRC-Emotion-Lexicon.htm&#34;&gt;NRC Word-Emotion Association Lexicon&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;To make the actual ridgeline plot, I used the &lt;code&gt;geom_density_ridges()&lt;/code&gt; extension to &lt;code&gt;ggplot()&lt;/code&gt;, provided in the &lt;code&gt;ggridges&lt;/code&gt; package. I created the ridgeline plot of the positive and negative sentiment groups separately, and then combined them together using the &lt;code&gt;ggarrange()&lt;/code&gt; function from the &lt;code&gt;egg&lt;/code&gt; package.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Making the plot!

# Creating the positive subplot
positive_plot &amp;lt;- nrc_df %&amp;gt;% 
  filter(sentiment %in% c(&amp;quot;joy&amp;quot;, &amp;quot;trust&amp;quot;, &amp;quot;anticipation&amp;quot;)) %&amp;gt;% 
  ggplot(aes(x = age_years, y = sentiment, fill = sentiment)) +
    geom_density_ridges(alpha = 0.8, show.legend = FALSE) +
    labs(x = &amp;quot;&amp;quot;, y = &amp;quot;&amp;quot;, title = &amp;quot;Kuczaj Corpus &amp;amp; Sentiment&amp;quot;,
         subtitle = &amp;quot;\nPositive Sentiments&amp;quot;) +
    scale_y_discrete(expand = c(0.01, 0)) +
    scale_x_continuous(expand = c(0.01, 0)) +
    scale_fill_manual(values = c(&amp;quot;#F6EFF7&amp;quot;, &amp;quot;#D0D1E6&amp;quot;, &amp;quot;#A6BDDB&amp;quot;)) +
    theme_ridges(grid = FALSE) +
    theme(plot.title = element_text(size = 22, hjust = -0.2),
          plot.subtitle = element_text(size = 18, face = &amp;quot;italic&amp;quot;),
          axis.text.y = element_text(size = 16, face = &amp;quot;bold.italic&amp;quot;))
    
# Creating the negative subplot
negative_plot &amp;lt;- nrc_df %&amp;gt;% 
  filter(sentiment %in% c(&amp;quot;anger&amp;quot;, &amp;quot;sadness&amp;quot;, &amp;quot;fear&amp;quot;)) %&amp;gt;% 
  ggplot(aes(x = age_years, y = sentiment, fill = sentiment)) +
    geom_density_ridges(alpha = 0.7, show.legend = FALSE) +
    labs(x = &amp;quot;Age in Years&amp;quot;, y = &amp;quot;&amp;quot;, title = &amp;quot;&amp;quot;,
         subtitle = &amp;quot;Negative Sentiments&amp;quot;) +
    scale_y_discrete(expand = c(0.01, 0)) +
    scale_x_continuous(expand = c(0.01, 0)) +
    scale_fill_manual(values = c(&amp;quot;#7999A8&amp;quot;, &amp;quot;#1C9099&amp;quot;, &amp;quot;#016C59&amp;quot;)) +
    theme_ridges(grid = FALSE) +
    theme(plot.subtitle = element_text(size = 18, face = &amp;quot;italic&amp;quot;),
          axis.text.y = element_text(size = 16, face = &amp;quot;bold.italic&amp;quot;))

# Combining into one and plotting
egg::ggarrange(positive_plot, negative_plot, ncol = 1, nrow = 2)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/project/final_vis_files/figure-html/plotting-1.png&#34; width=&#34;960&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;description-of-the-audience&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Description of the Audience&lt;/h1&gt;
&lt;p&gt;Since this data comes from a larger dataset that I am currently exploring in my research, potential audiences for this visualization might include my advisor, my colleagues, and other faculty at CSLU. In fact, I actually am planning on showing this visualization to my advisor tomorrow morning.
As for as potential audiences in a more general sense, this might include students or researchers interested in natural language processing, text mining, language acquisition, and sentiment analysis.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;description-of-the-graph-type&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Description of the Graph Type&lt;/h1&gt;
&lt;p&gt;A ridgeline plot visualizes the distribution of various groups, either as density plots or histograms, with the individual plots staggered vertically on a common x-axis and slightly overlapping each other. They are typically used to visualize how the aspects of a categorical variable change over time or space.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;representation-description&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Representation Description&lt;/h1&gt;
&lt;p&gt;I had never conducted any form of sentiment analysis on language acquisition data from CHILDES before and was curious if there would be any trends in sentiment types as the child grew older. Would he use more words that were associated with joy as he grew older? Would he use less? Would there be no discernable difference?&lt;/p&gt;
&lt;p&gt;After narrowing down the sentiment categories from ten to six, I chose to group the remaining ones into a “positive” group and a “negative” group. I made this decision after first plotting all six sentiments in one graph and seeing how difficult it was to read the plot at a quick glance. I thought that breaking the sentiments into two groups would make the information shown by the plot not only easier to read, but would it easier to make comparisons across categories by providing some order.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;how-to-read-it-what-to-look-for&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;How to Read it &amp;amp; What to Look For&lt;/h1&gt;
&lt;p&gt;Since the differences between sentiments are for the most part subtle, I find it easiest and most interesting to read this plot by first choosing two specific categories, and then comparing them to each other. Since the y-axis of this plot is a categorical variable, more information can be gathered if looking at subsections of the plot separately instead of looking at the entire plot at once.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;presentation&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Presentation&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;General Composition:&lt;/strong&gt; To reinforce the grouping of the sentiments into “positive” and “negative”, I chose to plot the two groups separately and stacked vertically. This preserved the common x-axis that is an essential characteristic of ridgeline plots, while also breaking apart plot making it easier to read.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Color:&lt;/strong&gt; Choosing the colors for this plot was difficult. I wanted to reflect the separation of sentiments into two groups while also being sure to emphasize that the sentiments were still categorical and not ordered. I tried to capture this with the colors by using a diverging color palette of distinct colors.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Annotation:&lt;/strong&gt; I used &lt;code&gt;theme_ridges()&lt;/code&gt; first with further customization of the theme afterwards. I chose to make the sentiments in bold and italicized to highlight the categories, and included subtitles of “Postiive Sentiments” and “Negative Sentiments” to show the grouping. Since the x-axis is the same for both plots, I chose to only include the y-axis label for the bottom plot.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;limitations&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Limitations&lt;/h1&gt;
&lt;p&gt;This plot is the result of an purely exploratory analysis venture that was limited by time constraints and not the result of an indepth, thorough analysis. Due to a lack of time, I was unable to normalize the data for differences in total word count across transcript. Any trends that this plot suggests may be due to confounding factors that were not controlled during analysis. Thus, this plot may not be an entirely accurate representation of the true nature of the dataset.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;an-early-draft&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;An Early Draft&lt;/h1&gt;
&lt;p&gt;This is an early draft plot that came before the sentiments were grouped into “positive” and “negative” and before I altered the general plot composition and colors. I had already chosen to reduce the total number of sentiments, but had only reduced it down to 8 for this plot. I decided to separate the sentiments into &lt;em&gt;positive&lt;/em&gt; and &lt;em&gt;negative&lt;/em&gt; groups and realizing that having them all on the same plot made it difficult to understand what was the plot was showing at a first glance.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Loading package for colors
library(beyonce)

# Making the plot
nrc_df %&amp;gt;% 
  filter(!sentiment %in% c(&amp;quot;positive&amp;quot;, &amp;quot;negative&amp;quot;)) %&amp;gt;% 
  ggplot(aes(x = age_years, y = sentiment, fill = sentiment)) +
    geom_density_ridges(alpha = 0.8, show.legend = FALSE) +
    labs(x = &amp;quot;Age in Years&amp;quot;, y = &amp;quot;&amp;quot;, title = &amp;quot;Kuczaj Corpus &amp;amp; Sentiment&amp;quot;) +
    scale_y_discrete(expand = c(0.01, 0)) +
    scale_x_continuous(expand = c(0.01, 0)) +
    theme_ridges(grid = FALSE) +
    scale_fill_manual(values = beyonce_palette(64))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/project/final_vis_files/figure-html/early%20draft-1.png&#34; width=&#34;960&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>A Sentiment Analysis of Child Language Acquisition Data</title>
      <link>/talk/ruser-group/</link>
      <pubDate>Sun, 01 Jan 2017 00:00:00 -0800</pubDate>
      
      <guid>/talk/ruser-group/</guid>
      <description>&lt;blockquote&gt;
&lt;p&gt;Join us for a night of four talks from students in OHSU&amp;rsquo;s Principles and Practice of Data Visualization, taught by Alison Hill, Steve Bedrick, and Jackie Wirz (&lt;a href=&#34;https://github.com/apreshill/data-vis-labs-2018&#34; target=&#34;_blank&#34;&gt;https://github.com/apreshill/data-vis-labs-2018&lt;/a&gt; | &lt;a href=&#34;https://apreshill.github.io/data-vis-labs-2018/&#34; target=&#34;_blank&#34;&gt;https://apreshill.github.io/data-vis-labs-2018/&lt;/a&gt;).&lt;/p&gt;

&lt;p&gt;Speakers:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Alex Salem: A Sentimental Analysis of Tolstoy&lt;/li&gt;
&lt;li&gt;Grace Lawley: A Sentiment Analysis of Child Language Acquisition Data&lt;/li&gt;
&lt;li&gt;Ryan Opel: Sole Mates: Analysis of Nike&amp;rsquo;s BIKETOWN Sneaker Bikes&lt;/li&gt;
&lt;li&gt;Alexandra Michel: Winning at Twitter with ggplot: What&amp;rsquo;s Up With Colorado Basin Water Use?&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Presentations will begin at 6:30 pm. Doors open 6:00 pm.&lt;/p&gt;

&lt;p&gt;Location: OHSU Robertson Life Science Building (RLSB) Room 3A001, at OHSU 2730 SW Moody Ave, Portland, OR 97201&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Twitter: @graceolawley&lt;br /&gt;
Github: gracelawley&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
