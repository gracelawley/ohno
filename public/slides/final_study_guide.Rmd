---
title: "CS 532 Final Exam Study Guide"
author: "Grace Lawley"
date: "9/11/2018"
output: 
  html_document:
    toc: true
    toc_float: true
    toc_depth: 1
    theme: "cosmo"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


# __Elementary Graph Algorithms__

## Representation of Graphs
### Adjacency-list representation
* __Needs size__ $\theta(|V|+|E|)$
* __Good for sparse graphs__ - $|E|$ much less than $|V|^2$
* Can be used for both directed and undirected graphs
* Can be easily adapted for weighted graphs by using a __weight function__
* Consists of an array $Adj$ of $|V|$ lists, one for each vertex in $V$. $Adj[u]$ consists of all the vertices adjacent to $u$ in $G$
* For directed graphs $\rightarrow$ the sum of the lengths of all of the adjacency lists is $|E|$
* For undirected graphs $\rightarrow$ the sum of the lengths of all of the adjacency lists is $2|E|$
* __Con:__ no quicker way to check if an edge $(u,v)$ is in the graph than to search for $v$ in the adjacency list $Adj[u]$

  
### Adjacency-matrix representation
* __Needs size__ $\theta(|V|^{2})$
* **Good for dense** graphs - $|E|$ close to $|V|^2$
* **Good for if we need to be able to quickly tell if there is an edge connecting two given vertices**
* Can be used for both directed and undirect graphs
* Assume vertices are numbered from 0 to $|V|-1$
* Can be used to represent a weighted graph by storing the weight of the edge as the entry for that edge in the matrix - only requires one bit per entry!
* If an edge does not exist, store $\infty$ as the entry value in the matrix 
* May prefer an adjacency-matrix over an adjacency-list when the graph is reasonably small


### Summary:
* __Adjacency Matrix__
  + Uses space $O(V^2)$
  + Can iterate over all edges in $O(V^2)$ time
  + Can answer "Is there an edge from $u$ to $v$?" in $O(1)$ time
  + Better for __dense__ graphs (i.e. lots of edges)
  + Can be used for weighted graphs
* __Adjacency List__
  + Uses space $O(V+E)$
  + Can iterate over all edges in $O(V+E)$ time
  + Can answer "Is there an edge from $u$ to $v$?" in $O(V_u)$ time
  + Better for __sparse__ graphs (i.e. fewer edges)  
  + Can be used for weighted graphs
* Universal sink question: 
  + Worst case run time of $O(V^2)$
  + The column of the node should be all 1's except for the square for itself
  + The row of the node should be all 0's

## <span style="color:red">Breadth-first search</span>
* Algorithm for searching a graph
* Given a graph and a source vertex, systematically explores the edges of G to "discover" every vertex that is reachable from $s$
* Computes the distance (smallest # of edges) from $s$ to each reachable vertex
* Produces a __breadth-first tree__ with root $s$ that contains all reachable vertices
  + For any vertex $v$ reachable from $s$, the simplest path in the breadth-first tree from $s$ to $v$ corresponds to a "shortest path" from $s$ to $v$ in G
  + Defines parent/predecessor, ancestor, and descendent relationship
* Expands the frontier between discovered and undiscovered vertices uniformly across the breadth of the frontier
    + i.e. discovers all vertices at distance $k$ from $s$ before discovering any vertices at distance $k+1$
* Attributes:
    + Color
    + Predecessor
    + Distance $\rightarrow$ distance from the source $s$ to the vertex $u$ computed by the algorithm
* __Colors__
    + __white__ = undiscovered (all vertices start out white)
    + __gray__ = discovered/on the frontier; may have some adjacent white vertices; represent the frontier between discovered and undiscovered vertices
    + __black__ = discovered; all adjacent vertices have been discovered
* Works on both directed and undirected graphs
* How it works:
    + Frontier of grey vertices kept as a fifo queue
    + First, put source/root node in the queue
    + Then, take the top node $u$ out of the queue
        + For each adjacent node $v$ that is white
        + Change its color to grey
        + Set $v.d =u.d+1$
        + Add $v$ to the queue
    + Change $u$ to black
* Note: queue will only ever contain grey vertices, i.e. represents the frontier
* __Running time:__ $O(V+E)$
  + Big O since the graph might not be entirely connected
  + If we represent the input graph by an __adjacency-matrix__ instead, the running time will be $O(V+V)$


## <span style="color:red">Depth-first search</span>
* Searches "deeper" in the graph whenever possible
* How it works:
    * Explores edges out of the most recently discovered vertex $v$ that still has unexplored edges leaving it
    * Once all of $v$'s edges have been explore, the search "backtracks" to explore dges leaving the vertex from which $v$ was discovered
    * Continues until all vertices that are reachable from the original source vertex have been discovered
    * If any undiscovered vertices remain, one is selected as the new source, and search is repeated
    * Entire process is repeated until every vertex has been discovered
* Data structures
   + Input graph is represented by an __adjacency-list__
   + Exploration is done using a stack
      + Can use either a stack object or a program stack from your recursive calls
* Vertex properties:
    + Predecessor
    + Discovery time-stamp
    + Finishing time-stamp
* Time-stamps tells you what order the nodes were visited in and about the structure of the graph itself
* Will output a forest (possibly)
* __Predecessor subgraph__ $G_\pi$
    + Is a forest of trees (might just be one tree)
    + Vertex $v$ is a descendent of vertex $u$ in the depth-first forest iff $v$ is discovered during the time in which $u$ is gray
* Discovery and finishing times have __parenthesis structure__
    + If we represent the discovery of vertex $u$ with a left parenthesis "(u" and represent its finishing by a right parenthesis "u)"
    + Then the history of discoveries and finishes makes a well-formed expression int he sense that the parentheses are properly nested
* __White-path Theorem__
    + In a depth-first forest of a (directed or undirected) graph, vertex $v$ is a descendent of vertex $u$ iff at the time $u.d$ that the search discovers $u$, there is a path from $u$ to $v$ consisting entirely of white vertices
* __Classification of edges__
    1. __Tree edges__ are edges in the depth-first forest $G_\pi$. Edge $(u,v)$ is a tree edge if $v$ was discovered by exploring edge $(u,v)$
    2. __Back edges__ are those edges $(u,v)$ connecting a vertex $u$ to an ancestor $v$ in a depth-first tree. We consider self-loops, which may occur in directed graphs, to be back edges
    3. __Forward edges__ are those nontree edges $(u,v)$ connecting a vertex $u$ to a descendant $v$ in a depth-first tree
    4. __Cross edges__ are all other edges. They can go between vertices in the same depth-first tree, as long as one vertex is not an ancestor of the other, or they can go between vertices in different depth-first trees
* Colors of the four types of edges
    + DFS can classify some edges as they are encountered by the color of the second vertex
    + When we first explore an edge $(u,v)$, the color of the vertex $v$ tells us something about the edge
        + __White__ indicates a tree edge
        + __Grey__ indicates a back edge
        + __Black__ indicates a forward or cross edge
* __Theorem 22.10__
    + In a DFS of an __undirected graph__, every edge is either a tree edge or a back edge. 
* __Running time:__ $\theta(V+E)$
  
  
## Summary:
+ __BFS__ gives you:
  1. The shortest path from s
  2. All reachable paths from s
+ __DFS__ gives you:
  + Discovery and finish times
  + Forest


## <span style="color:red">Topological sort</span>
+ Can use DFS to perform a topological sort of a directed acyclic graph (a.k.a. dag)
+ A __topological sort__ of a dag $G$ is a linear ordering of all its vertices such that if $G$ contains an edge $(u,v)$, then $u$ appears before $v$ in the ordering 
    + If a graph contains a cycle, then no linear ordering is possible
    + Graph might just give a partial ordering
    + Many different linear orderings might be possible
* Can view a topological sort of a graph as an ordering of its vertices along a horizontal line so that all directed edges go from left to right
* Implementation:
    1. Run a DFS on the graph to compute the finishing times $v.f$ for each vertex $v$
    2. As each vertex is finished, insert it into the front of a linked list
    3. Return the linked list of vertices
* In summary: topologically sorted vertices appear in __reverse order__ of their finishing times
* __Running time:__ $\theta(V+E)$
    + Since DFS takes $\theta(V+E)$ to run and it takes $O(1)$ to insert each of the vertices onto the front of the linked list


## <span style="color:red">Strongly connected components</span>
* A strongly connected component of a directed graph is a maximal set of vertices $C\subseteq V$ such that for every pair of vertices $u$ and $v$ in $C$, vertices $u$ and $v$ are reachable from eacother
    + This partitions the vertices into distinct sets
* Can decompose a directed graph into its strongly connected components by using two depth-first searches
* Many algorithms that work with directed graphs start with such a decomposition
    + After decomposing the graph into strongly connected components
    + Such algorithms run separately on each one and then combine the solutions according to the structure among components
* To find strongly connected components of a graph G, first find the __tranpose__ of G, $G_T$
    + Create the tranpose by reversing the direction of all edges
    + For an adjacency-list representation, takes time $O(V+E)$ to create the tranpose
    + $G$ and $G_t$ will have exactly the same strongly connected components
* Algorithm $STRONGLY-CONNECTED-COMPONENTS(G)$
    + Computes the strongly connected components of a directed graph G
    + Uses two depth-first searches, one on $G$ and one on $G_t$
    1. Run DFS on G
    2. Compute tranpose
    3. Run DFS on tranpose, but in the main loop of DFS, consider the vertices in order of decreasing $u.f$ as computed in (1)
    4. Output the vertices of each tree in the depth-first forest formed in (3) as a separate strongly connected component
* Key property: component graph is a dag
* __Running time:__ $\theta(V+E)$

# __Minimum Spanning Trees__
* __Spanning tree__
* __Minimum-spanning tree problem__
  + $G = (V,E)$ is a connected, unidrected graph with weighted edges
  + Find a minimum weight subset of edges, $T$, that connects every vertex and is acyclic 
  + T is called a __spanning tree__. Since it is acylic and connects all vertices, it must form a tree that "spans" the graph G
  + There are $V-1$ edges in the minimum spanning tree 

## <span style="color:red">Generic Method</span>
* Let $G = (V,E)$ with a weight function $w: E \rightarrow \mathbb{R}$. Find a minimum spanning tree for $G$
* Generic method grows the minimum spanning tree one edge at a time
  + Start with a set of edges A
  + Loop invariant: Prior to each iteration, $A$ is a subset of some minimum spanning tree
  + At each step, determine an edge $(u,v)$ that can be added to $A$ without violating the loop invariant
    - This edge is called a __safe edge__ for $A$, since it can be added safely to $A$ without violating the loop invariant 
* Method is greedy and optimal if we can deteremine an optimal edge at each step 
* Terms:
  + A __cut__ $(S,V-S)$ of an undirected graph $G = (V,E)$ is a partition of $V$
  + We say that an edge $(u,v)\in E$ __crosses__ the cut $(S,V-S)$ if one of its endpoints is in $S$ and the other is in $V-S$
  + We say that a cut __respects__ a set $A$ of edges if no edge in A crosses the cut
  + An edge is a __light edge__ crossing a cut if its weight is the minimum of any edge crossing the cut
* __Theorem 23.1__: how to recognize safe edges
  1. Let $G = (V,E)$ be a connected, undirected graph with $w: E \rightarrow \mathbb{R}$
  2. Let $A$ be a subset of $E$ that is included in some minimum spanning tree for $G$
  3. Let $(S,V-S)$ be any cut of $G$ that respects $A$
  4. Let $(u,v)$ be a light edge crossing $(S,V-S)$
  5. Then edge $(u,v)$ is safe for $A$
  + In plain English:
    + If you have $A$ a partial minimum spanning tree for $G$
    + Pick some vertices to make a cut that respects $A$
    + Find an edge of minimum weight that cross the cut
    + Is it a safe edge? If yes, add it to $A$
* __Runtime:__ the while loop executes $|V|-1$ times

## <span style="color:red">Kruskal's algorithm</span>
* Summary: The set $A$ is a forest whose vertices are all those of a given graph. The safe edge added to $A$ is always a least-weight edge in the graph that connects two distinct components (a.k.a. trees)
* Special case of the generic minimum-spanning tree method
* Is a greedy algorithm because at each step it adds to the forest an edge of least possible weight
* Implementation:
  + Uses a disjoint-set data structure to maintain several disjoint sets of elements
  + Initialize the set A as an empty set
  + Create $|V|$ trees, each containing one vertex
  + Cycle through the edges from lowest weight to highest weight
  + For each edge $(u,v)$, check if the endpoints $u$ and $v$ belong to the same tree
  + If they do, the edge $(u,v)$ can't be added to the forest without creating a cycle, continue to next edge
  + If they belong to different trees, add the edge $(u,v)$ to $A$ and combine the two trees by $u$ and $v$
* Running time depends on how the disjoint-set data structure is implemented. Assume union-by-rank and path-compression heuristics are used
  + __Running time__ = $O(ElogE)$ = $O(ElogV)$

## <span style="color:red">Prim's algorithm</span>
* Summary: The set $A$ forms a single tree. The safe edge added to $A$ is always a least-weight edge connecting the tree to a vertex not in the tree
* Special case of the generic minimum-spanning tree method
* Has the property that the edges in the set $A$ always form a single tree
* Start with an arbitary vertex and grow until the tree spans all the vertices in V
  + At each step add a light edge that connects $A$ to an isolated vertex
  + Only safe edges are ever added, so at termination $A$ will be a minimum spanning tree
* Is a greedy algorithm since at each step it adds to the tree an edge of least possible weight
* Implementation
  + Uses a min-priority queue data struture
  + Set the key (i.e. the minimum weight of any edge connecting that vertex to a vertex in the tree, equals $\infty$ if no such edge) of the root vertex, $r$, to 0 and the key for all other vertices to $\infty$
  + Set the parent of each vertex to $NIL$
  + Initialize the min-priority queue $Q$ to contain all vertices
  + While the $Q$ is not empty, extract the vertex, $u$, with the minimum key value and add it to $A$
  + For all vertices $v$ adjacent to $u$, see if $u$ provides a better way to $A$ (via $u$)
  + If it does, update the key and parent attributes of $v$
* Running time depends on how the min-priority queue is implemented. Assume we implement $Q$ as a binary min-heap (as opposed to a Fibonacci heap)
  + __Running time__ = $O(E+VlogV)$
  


# __Single-Source Shortest Paths__
## Shortest-path problems:
  + Given a weighted, directed graph $G=(V,E)$, with weight function $w: E \rightarrow \mathbb{R}$
  + The weight of a path is the sum of the weights of its constituent edges
  + $\delta(u,v)$ is the __shortest-path weight__ from $u$ to $v$
  + If a path from $u$ to $v$ does not exist, $\delta(u,v)=\infty$
  + A __shortest path__ from vertex $u$ to vertex $v$ is any path $p$ with weight $w(p)=\delta(u,v)$
* The breadth-first-search elementary graph algorithm is a shortest-paths algorithm that works on unweighted graphs

## Variants:
  1. __Single-source shortest-paths problem__: 
    + Find a shortest path from a given source point to all other points
  2. __Single-destination shortest-paths problem__:
    + Find a shortest path to a given destination point from all other points
    + Reverse the direction of all edges by transposing the graph to change to a single-source problem
  3. __Single-pair shortest-path problem__:
    + Find a shortest path from $u$ to $v$ for given vertices $u$ and $v$
  4. __All-pairs shortest-paths problem__$:
    + Find a shortest path from $u$ to $v$ for every pair of vertices $u$ and $v$

## Optimal substructure of a shortest path
  + Shortest path algorithms typically rely on the property that a shortest path between two vertices contains other shortest paths within it
  + Optimal substructure is one of the key indicators that dynamic programming and the greedy method might apply

## Negative-weight edges
  + Each time through a negative weight cycle gives a lower weight
  + If a negative-weight cycle is reachable from $s$, the shortest-path weight $\delta(s,v)$ is not well defined
  + If not, then the shortest-path weight $\delta(s,v)$ is well defined
  + If there is a negative-weight cycle on some path from $s$ to $v$, we define $\delta(s,v)=-\infty$
  + Dijkstra's algorithm assumes that all edge weights in the input graph are nonnegative
  + Bellman-Ford algorithm allows negative-weight edges in the input graph and will produce a correct answer as long as no negative-weight cycles are reachable from the source

## Cycles
  + Cannot contain a negative-weight cycle
  + Cannot contain a positive-weight cycle
    + Removing the cycle from the path produces a path with hte same source and destination vertices and a lower path weight
  + 0-weight cycles:
    + We can repeatedly remove these cycles from the path until we have a shortest path that is cycle free
    + Therefore, without loss of generality we can assume that when we are finding shortest paths, they have no cycles, i.e. they are simple paths
  + Can restrict ourselves to shortest paths of at most $|V|-1$ edges

## Representing shortest paths
  + Represent shortest paths similarly to how we represented breadth-first trees in "Elementary Graph Algorithms"
  + Each vertex, $v$, has a predecessor, $v.\pi$ that is either another vertex or $NIL$
  + Pseudocode in textbook set the $\pi$ attributes so that the chain of predecessors originating at a vertex $v$ runs backwards along a shortest path from $s$ to $v$
  + __Predecessor subgraph:__ $G_{\pi}=(V_{\pi},E_{\pi})$
  + At the termination of the algorithm, $G_{\pi}$ is a __shortest-paths tree__: a rooted tree containing a shortest path from the source $s$ to every vertex that is reachable from $s$
    + A shortest-path tree is like the breadth-first tree but it contains shortest paths from the source defined in terms of edge weights instead of number of edges
    + Shortest paths and shortest-path trees are not necessarily unique

## Relaxation
  + The process of __relaxing__ an edge $(u,v)$ consists of testing whether we can improve the shortest path to $v$ found so far by going through $u$ and, if so, updating $v.d$ and $v.\pi$
  + Strategy: start with an upper bound and keep revising it when you find a lower cost
  + Pseudocode in textbook performs a relaxation step on edge $(u,v)$ in $O(1)$ time
  + Relaxation is the only means by which shortest-path estimates and predecessors change
  + The algorithms in this chapter differ in how many times they relax each edge and in which order they relax edges
    + Dijkstra's algorithm and the shortest-paths algorithm for DAG's relax each edge exactly once
    + Bellman-Ford algorithm relaxes each edge $|V|-1$ times 

## Properties of shortest paths and relaxation
+ __Triangle inequality__
  + For any edge $(u,v)\in E$, we gave $\delta(s,v)\leq \delta(s,u)+w(u,v)$
+  __Upper-bound property__
  + We always have $v.d\geq \delta(s,v)$ for all vertices $v\in V$, and once $v.d$ achieves the value $\delta(s,v)$, it never changes
+ __No-path property__
  + If there is no path from $s$ to $v$, then we always have $v.d=\delta(s,v)=\infty$
+ __Convergence property__
  + If $s\rightsquigarrow u \rightarrow v$ is a shortest path in $G$ for some $u,v\in V$, and if $u.d=\delta(s,u)$ at any time prior to relaxing edge $(u,v)$, then $v.d=\delta(s,v)$ at all times afterward
* __Path-relaxation property__
  + If $p=<v_{0},v_{1},...,v_{k}>$ is a shortest path from $s=v_{0}$ to $v_{k}$, and we relax the edges of $p$ in the order $(v_{0},v_{1}),(v_{1},v_{2}),...,(v_{k-1},v_{k})$, then $v_{k}.d=\delta(s,v_{k})$. This property holds regardless of any other relaxation steps that occur, even if they are intermixed with relaxations of the edges of $p$
* __Predecesor-subgraph property__
  + Once $v.d=\delta(s,v)$ for all $v\in V$, the predcessor subgraph is a shortest-paths tree rooted at $s$

## <span style="color:red">Bellman-Ford algorithm</span>
* Solves the single-source shortest paths problem in the general case in which edges can have negative weight
* Can detect whether a negative-weight cycle is reachable from the source
* Graph is stored in an adjacency-list representation
  + Weights are stored with each edge
  + Once we know if an edge exists, an determine the weight in $O(1)$ 
* Returns a boolean value indicating whether or not there is a negative-weight cycle that is reachable from the source
  + If there is such a cycle, the algorithm indicates that no solution exists
  + If there isn't such a cycle, the algorithm produces the shortest paths and their weights
* The algorithm relaxes edges, progressively decreasing an estimate $v.d$ on the weight of a shortest path from the source $s$ to each vertex $v\in V$ until it achieves the actual shortest path-weight $\delta(s,v)$
* How it works:
  + Progressively decreases the estimate $v.d$ by relaxing each edge in the graph
  + The $v.d$ values get better and better with each iteration, eventually convering to their optimal value
  + After $|V|-1$ rounds, each vertex will reach its minimum value
* Bellman-Ford is used in Reinforcement Learning
  + To update estimates of what sequence of actions to perform to finish a task
* Seems to be inefficient
  + Doing a lot of $\theta(V)$ passes to examine each edge
  + Blindly examines all edges
* __Running time:__ $O(VE)$

## <span style="color:red">Single-source shortest path in directed acyclic graphs (dag)</span>
* A linear-time algorithm for computing shortest paths from a single source in a directed acyclic graph
* Graph is stored in an adjacency-list representation
  + Weights are stored with each edge
  + Once we know if an edge exists, an determine the weight in $O(1)$ 
* In a dag, shortest paths are always well defined, since even if there are negative-weight edges, no negative-weight cycles can exist
* Algorithm: 
  + Starts by topologically sorting the dag to impose a linear ordering on the vertices
  + If the dag contains a path from vertex $u$ to $v$, then $u$ precedes $v$ in the topological sort
  + Only need to make one pass over the sorted vertices
  + As we process each vertex, we relax the edge that leaves the vertex
* Each edge is relaxed exactly once
* At termination, $v.d=\delta(s,v)$ for all vertices
* Cannot use this algorithm for arbitrage because arbitrage depends on cycles
* Applications:
  + Used in determining critical paths in __PERT chart__ analysis on project management
  + Edges represent jobs to be performed and edge weights represent the times required to perform particular jobs 
  + A path through this dag represents a sequence of jobs that must be performed in a particular order
  + A __critical path__ is a longest path through the dag, corresponding to the longest time to perform any sequence of jobs
    + The weight of a critical path provides a lower bound on the total time to performa ll the jobs
    + One way to find the critical path is to negate the edge weights and run $DAG-SHORTEST-PATHS$
* __Running time:__ $\theta(V+E)$

## <span style="color:red">Dijkstra's algorithm</span>
* Has a lower running time than Bellman-Ford but requires non-negative edge weights
* Solves the single-source shortest-paths problem on a weighted, directed graph G for the case in which all edge weights are nonnegative
  + Can have 0-weight edges
  + Can have cycles, but no negative weight cycles
* With a good implementation, the running time of Dijkstra's algorithm is __lower__ than that of Bellman-Ford
* Graph is stored in an adjacency-list representation
  + Weights are stored with each edge
  + Once we know if an edge exists, an determine the weight in $O(1)$ 
* How it works:
  + The algorithm maintains a set $S$ of vertices whose final shortest-path weights from the source $s$ have already been determined
  + Algorithm repeatedly selects the vertex $u\in V-S$ with the minimum shortest-path estimate, adds $u$ to $S$, and relaxes all edges leaving $u$
* Resembles a breadth-first search
  + Orders vertices by distance from the source (since the vertices are put into a queue)
*  Resembles Prim's algorithm for computing minimum spanning trees
  + Both Prim's and Dijkstra's use a min-priority queue to find the "lightest" vertex outside of a given set, add this vertex into the set/tree, and adjust the weights of the remaining vertices outside the set/tree accordingly
* Is a greedy strategy since it always chooses the "lightest" or "closest" vertex in $V-S$ to add to set $S$
* The key to proving that Dijkstra's algorithm computes the shortest path is to show that each time it adds a vertex $u$ to the set $S$, we have $u.d=\delta(s,u)$
* Implementation:
  + Use a min-priority queue $Q$ of vertices, keyed by their $d$ values
  + Initialize all vertices in $G$
  + Set $d=0$ for the source vertex and set $d=\infty$ for all other vertices
  + Set $\pi=NIL$ for all vertices
  + Add all vertices to the min-priority queue $Q$ (note: no vertices are inserted after this point)
  + While the queue is not empty, extract a vertex $u$
  + Add $u$ to the set $S$
  + Then, for each vertex $v$ that is adjacent to $u$, relax each edge $(u,v)$, thus updating the estimate $v.d$ and the predecessor $v.\pi$ if we can improve the shortest path to $v$ found so far by going through $u$
* __Running time:__ $\theta(ElogV)$ (assuming all vertices are reachable)

## Summary:
+ Bellman-Ford, DAG Shortest Path, and Dijkstra's algorithm all work on weighted, directed graphs
+ The Relaxation Procedure is the basis of all three of these algorithms
+ __Bellman-Ford__
  + Can work on graphs wiht cycles and negative edges
  + Can detect negative cycles
  + Slowest of the three
  + __Running time:__ $\theta(VE)$
+ __DAG Shortest Path__
  + Restricted to DAG's (but much faster than Bellman-Ford!)
  + Fastest of the three
  + __Running time:__ $\theta(V+E)$
+ __Dijkstra's Algorithm__
  + No negative edges but can have 0-weight edges
  + Can have cycles, but no negative weight cycles
  + 2nd fastest of the three
  + __Running time:__ $\theta(ElogV)$ (assuming all vertices are reachable)


# __All-Pairs Shortest Paths__
* Problem: How to find shortest paths between all pairs of vertices in a graph
* One solution:
  + Run a single-source shortest-paths algorithm $|V|$ times, once for each vertex as the source
  + If the graph has no negative edges (e.g. route finding)
    + Can use Dijkstra's algorithm that runs in $\theta(ElogV)$
    + If the graph is sparse, running time would be $\theta(VElogV)$ 
    + If the graph is dense, running time would be $\theta(V^{3}logV)$
  + If the graph has negative weight edges and cycles
    + Can use Bellman-Ford algorithm that runs in $\theta(EV)$
    + If the graph is sparse, running time would be $\theta(EV^2)$
    + If the graph is dense, running time would be $\theta(V^4)$
* Chapter introduces other ways to do this faster
* Most of the algorithms in this chapter use an *adjacency-matrix representation* of the graph
* General set-up:
  + Assume that vertices are numbered $1, 2,...,|V|$
  + Input is an $n x n$ matrix $W$ representing the edge weights of an $n$-vertex directed Graph $G=(V,E)$
  + Negative weight edges are allowed, but assuming for now that the input graph contains no negative-weight cycles
  + Output will be an $n x n$ array $D=(d_{ij})$ where entry $d_{ij}$ contains the weight of a shortest path from vertex $i$ to vertex $j$
    + So if $\delta(i,j)$ represents the shortest-path weight from $i$ to $j$, then $d_{ij}=\delta(i,j)$ at termination
  + Also will need a predecessor matrix $\Pi =(\pi_{ij})$
    + Where $\pi_{ij}=NIL$ if either $i=j$ or there is no path from $i$ to $j$,
    + and otherwise $\pi_{ij}$ is the predecessor of $j$ on some shortest path from $i$
    + So, row $i$ will contain all of the predecessors for the shortest paths originating at $i$

## Shortest paths and matrix multiplication
* This section presents a dynamic-programming algorithm for the all-pairs shortest paths problem on a directed graph $G$ that can have negative edges, but no negative cycles
* Recap of steps for developing a dynamic-programming algorithm (chapter 15)
  1. Characterize the structure of an optimal solution
  2. Recursively define the value of an optimal solution
  3. Compute the value of an optimal solution in a bottom-up fashion
  4. Construct an optimal solution from computed information (done in the exercises for this chapter)
* __1. The structure of a shortest path__
  + Let $p$ be the shortest path from $u$ to $v$ and $p=<v_{0}, v_{1},...,v_{k}>$
  + For a vertex $v_{j}$, path $<v_{0}, v_{1},...,v_{j}>$ is the shortest path for $v_{0}$ to $v_{j}$
  + For a vertex $v_{i}$ where $i<j$, the path <v_{i}, v_{1},...,v_{j}>$ is the shortest path for $v_{i}$ to $v_{j}$
  + So $\delta(v_{0}, v_{j})=\delta(v_{i}, v{j}) + w(v_{0}, v_{i})$ 
* __2. A recursive solution to the all-pairs shortest-paths problem__
  + Let $l_{ij}^{(m)}$ be the min weight of any path from $i$ to $j$ that contains at most $m$ edges
  + $l_{ij}^{(0)}$ is 0 if $i=j$
  + $l_{ij}^{(0)}$ is $\infty$ if $i\neq j$
  + $l_{ij}^{(m)} = min(l_{ij}^{(m-1)}, \min\limits_{1\leq k\leq n}\{ l_{ik}^{(m-1)}+w_{kj}\})$
  + $l_{ij}^{(m)} = \min\limits_{1\leq k\leq n}\{ l_{ik}^{(m-1)}+w_{kj}\}$, since $w_{jj}=0$ for all $j$
* __3.Computing the shortest-path weights bottom-up__
  + Taking as our input the matrix $W=(w_{ij})$
  + Compute a series of matrices $L^{(1)}, L^{(2)},...,L^{(n-1)}$
  + Where for $m = 1, 2,..., n-1$, we have $L^{(m)}=(l_{ij}^{(m)})$
  + The final matrix $L^{(n-1)}$ contains the actual shortest-path weights
  + The heart of the algorithm is the procedure $EXTEND-SHORTEST-PATHS(L,W)$
      + Given matrices $L^{(m-1)}$ and $W$, returns the matrix $L^{(m)}$
      + Extends the shortest paths computed so far by one more edge
      + __Running time:__$\theta(n^{3})$
  + Next step is the procedure $SHOW-ALL-PAIRS-SHORTEST-PATHS(W)$
      + __Running time:__ $\theta(n^{4})$
  + Note: we can change $EXTEND-SHORTEST-PATHS(L,W)$ to use matrix multiplication: $SQUARE-MATRIX-MULTIPLY(A,B)$
      + __Running time:__ $\theta(n^{4})$
* Improving the running time:
    + Can use a __repeated squaring__ technique to improve the running time since matrix multiplication is associative
        + $L^{(1)}$ is just $W$
        + $L^{(2)}$ is like $W$ but for hops of at most length 2
        + To compute $L^{(4)}$, we can call a routine on $L^{(2)}$ and $L^{(2)}$
        + To compute $L^{(8)}$, we can call a routine on $L^{(4)}$ and $L^{(4)}$
        + Can compute $L^{(n-1)}$ in $O(\lfloor logn\rfloor)$ steps
        + __Running time:__ $O(n^{3}logn)$
 
## <span style="color:red">Floyd-Warshall Algorithm</span>
* Solves the all-pairs shortest-paths problem on a directed graph using a different dynamic-programming approach
* Negative weight edges are allowed but negative-weight cycles are not
* Floyd-Warshall algorithm characterizes the structure of a shortest path (i.e. optimal substructure) differently than above
* __Running time:__ $\theta(V^{3})$


# __String Matching__
* __String-matching problem__ = find all valid shifts with which a pattern $P$ occurs in a given text $T$
* $w\sqsubset x\rightarrow$ w is a __prefix__ of x
* $w\sqsupset x\rightarrow$  w is a __suffix__ of x
* __Comparing two equal-length strings__
    + Testing "x==y" takes $\theta(t+1)$
    + Need to compare $t+1$ characters to encounter the first character where the strings differ


## <span style="color:red">The naive string-matching algorithm</span>
* __Running time:__
    + __Preprocessing:__ $0$
    + __Matching:__ $O((n-m+1)m)$

## <span style="color:red">The Rabin-Karp algorithm</span>
* __Running time:__
    + __Preprocessing:__ $\theta(m)$
    + __Matching:__ $O((n-m+1)m)$
    
## <span style="color:red">String matching with finite automata</span>
* __Running time:__
    + __Preprocessing:__ $\theta(|m\Sigma|)$
    + __Matching:__ $\theta(n)$


# __Summary of Run Times__
* Elementary Graph Algorithms:
  + __BFS:__ $O(V+E)$
  + __DFS:__ $\theta(V+E)$
  + __Topological sort:__ $\theta(V+E)$
  + __Strongly connected components:__ $\theta(V+E)$
* Minimum Spanning Trees:
  * __Kruskal's algorithm:__ $O(ElogV)$
  * __Prim's algorithm:__ $O(E+VlogV)$
* Single-Source Shortest Paths:
  * __Bellman-Ford algorithm:__ $O(VE)$ 
  * __DAG Shortest Path:__ $\theta(V+E)$
  * __Dijkstra's algorithm:__ $\theta(ElogV)$
* All-Pairs Shortest Paths:
  + __Floyed-Warshall Algorithm:__ $\theta(V^{3})$
* String Matching:
  + __Brute force approach:__
  + __Naive string-matching algorithm:__ 
  + __Rabin-Karp algorithm:__ 
        + Preprocessing: $\theta(m)$
        + Matching: $O((n-m+1)m)$
  
  
